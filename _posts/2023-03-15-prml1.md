---
layout: post
title:  prml 1
categories: mathematics
---

- 2022/03/15 스터디 1주차
## Polynomial curve fitting
- $\mathbf x \in \mathbb R^n, \mathbf t \in \mathbb R^n$
- $y(x, \mathbf w) = \sum_{j=0}^M w_jx^j$
  - hyperparameter $M$ 을 어떻게 정해야 하는가? - overfitting, generalization
- $E(\mathbf w) = \frac{1}{2} \sum_{n=1}^N \\{y(x_n, \mathbf w) - t_n\\}^2$
- $E_{\text{RMS}} = \sqrt{2E(\mathbf w^*) / N}$
  - independent from size of data set
  - same scale with target value $\mathbf t$
- $M$ 이 커질수록 polynomial curve 가 oscillating 하게 되고, 이는 overfitting 을 야기 - 차수가 커질수록 유연하고, random noise 에 tuned
- $\tilde E(\mathbf w) = \frac{1}{2} \sum_{n=1}^N (y(x_n, \mathbf w) - t_n)^2 + \frac{\lambda}{2} \vert\vert\mathbf w\vert\vert^2$
  - shrinkage method in statistics literature
  - regression
  - ridge regression - quadratic regularizer
  - weight decay in the context of neural network

## Probability Theory
- $x = g(y), \ P_y(y) = P_x(x) \rvert \frac{dx}{dy}\lvert = P_x(g(x))g'(x)$
  - $P_x(x)\delta x \approxeq P_y(y)\delta y$
  - Nonlinear change of variable, Jacobian factor
  - The concept of the maximum of a probability density is dependent on the choice of variable
  - But why use absolute value of the amount of change?
- $\mathbb E[f] = \sum_x P(x)f(x)$
- $\mathbb E[f\vert y] = \sum_x P(x\vert y)f(x, y)$
- $\mathbb E_x[x, y]$ is a function of $y$
- $\text{cov}[\mathbf x, \mathbf y] = \mathbb E_{\mathbf x, \mathbf y}[\mathbf x\mathbf y^\intercal] - \mathbb E[\mathbf x] \mathbb E[\mathbf y]$
- $P(\mathbf w \vert \mathcal D) = \frac{P(\mathbf D\vert\mathbf w)P(\mathbf w)}{P(\mathbf D)}$
  - $P(\mathcal D) = \int P(\mathcal D\vert\mathbf w)P(\mathbf w) d\mathbf w$
  - posterior $\propto$ likelihood $\times$ prior
- frequentist vs bayesian
  - likelihood
  - estimator, estimate, error bars
    - maximum likelihood
    - bootstrap
- MLE 는 구조적으로 variance 를 과소평가함 - precision 을 과대평가함 -> overfitting

## Model Selection
- validation
  - To prevent the overfitting to test data in HPO
- cross-validation, LOOCV
- Akaike information criterion, Bayesian information creierion
  - MLE 의 bias 를 막기 위해 많은 information criteria 가 등장
  - AIC
    - $\text{ln} (P(\mathcal D \vert \mathbf w_{\text{ML}})) - M$
    - 통계 시간에는 $-2\text{ln(L)}+2k$ 로 배우고 작을수록 좋다고 했는데-
    - $\text{ln}(L)$ 은 모델의 적합도(가능도)이고, $k$ 는 파라미터 수이다
    - 말 그대로 파라미터 개수를 패널티로 추가한 것이다
  - BIC, SIC (Schwarz information criterion)
    - $k\text{ln}(n) - 2\text{ln} (P(\mathcal D \vert \mathbf w_{\text{ML}})$
    - AIC 에서 $M$ 을 $k\text{ln}(n)$ 으로 바꾼 형태
    - 패널티가 더 큼
- model selection 은 정보 이론과 깊은 연관을 맺고 있음.

## The Curse of Dimensionality
- feature 개수가 $D$ 개이고, $M$ 차원 polynomial curve fitting 을 한다고 하면, 파라미터 개수는 $D^M$ 개가 필요하다.
- exponential 이 아니긴 하지만 power law growth 도 간과하긴 어렵다
- 원점을 중심으로 두는 구체(sphere) 를 생각했을 때, 구체가 존재하는 차원의 차수가 커질수록 껍질에 대부분의 volume 이 집중되는 현상을 관찰할 수 있다.
  - 책의 figure 1.22
  - figrue 1.23 는, $D$ 차원 정규분포를 극좌표계로 바꾼 뒤 with respect to $\theta$ 로 summation 한 분포를 그린 것이다.
    - 신기하게도 $D$ 가 커질수록 바깥쪽으로 분포가 쏠리는 현상을 관찰할 수 있다

## Decision Theory
- $P(\text{mistake}) = \int_{\mathcal R_1}P(\mathbf x, \mathcal C_2)d\mathbf x + \int_{\mathcal R_2}P(\mathbf x, \mathcal C_1)d\mathbf x$
- $P(\text{correct}) = \sum_{k=1}^K\int_{\mathcal R_k}P(\mathbf x, \mathcal C_k)d\mathbf x$
- $\mathbb E[L] = \sum_k \sum_j \int_{\mathcal R_j} L_{kj}P(\mathbf x, \mathcal C_k)d\mathbf x$
  - $L_{kj}$ 는 loss matrix - 혼동 행렬과 비슷한 형태, 각 element 가 가중치를 의미함
  - 이걸 최소화하는 decision boundary 를 구해야 하고, 이는 bayesian Decision Theory 등을 사용해 구할 수 있다. 책에서는 다루지 않았음.
    - $\sum_k L_{kj}P(\mathcal C_k \vert \mathbf x)$ 을 각 $\mathcal R_j$ 마다 구하고 가장 작은 것을 선택. $P(x)$ common factor 이므로 제거.
      - $$g_i(\mathbf x) = P(c_i \vert \mathbf x) \\ \rightarrow g_i(\mathbf x) = P(\mathbf x \vert c_i)P(c_i) \\ \rightarrow g_i(\mathbf x) = \text{ln}P(\mathbf x \vert c_i) + \text{ln} P(c_i)$$
      - 이런 느낌? $P(\mathbf x \vert c_i)$ 을 normal distribution 등으로 가정하고 풀 수 있음.
- reject option 이라는 것이 있어서, $p(\mathcal R_1 \vert \mathbf x)$ 와 $p(\mathcal R_2 \vert \mathbf x)$ 분포 사이의 애매한 부분에서는 결정을 포기할 수 있음
  - 어떤 지점에서의 확률이 특정 threshold 에 도달하지 못하면 reject
  - $k$ 개의 클래스가 있을 때 threshold 는 $\frac{1}{k}$ 보다 크거나 같고 1보다 작을 것임
  - 기대 손실을 줄이는 데에 활용 가능
- 



---

first draft: 2022.03.15 23:44