---
layout: post
title: Neural Graph Collaborative Filtering
categories: dl
---

# INDEX
- [1. Introduction](#1-introduction)
- [4. Approach](#4-approach)

# 1. Introduction
- 온라인 서비스에서 사용자의 행동은 계속해서 바뀜 - dynamic and evolving over time
  - 이를 파악하는 것이 중요함  
  -> sequential recommendation
  - caracterize sequential user-item interactions
- 나아가, item attribute 같은 rich contexual information 을 사용하는 neural sequential recommenders 가 등장하기 시작
- 하지만, 이런 방법들은 shortcommings 가 명확한데
  1. Only rely on the item prediction loss to learn the entire model
      - context data 가 추가되었을 때, 그와 관련된 파라미터들도 같은 objective function 에 의해 학습됨 -> data sparsity 에 민감 (???) - 아무튼 최적화에 어려움을 겪는 듯 - limited supervision signal
  2. Overemphasize the final performance
      - 좋은 data representation 을 capture 하지 못해도 성능이 좋게 나온다고 함
      - BERT 등의 경우를 통해 effective data representation 을 찾는 게 중요하단 걸 알 수 있음
- 정리하자면, limited supervision signal 과 ineffective data representation 이 문제임
- 이런 이유에서, sequential recommendation 을 위한 새로운 학습 패러다임이 필요하다고 생각
- 이때 SSL 은 좋은 방법이 될 수 있는데,
  - aim to let the model learn from the intrinsic structure of the raw data
  - 보통 raw data 로부터 training signals 를 만든 뒤, pre-train 한다
    - additionally devised optimization objectives 를 통해 - sufficient supervision signals!
      - intrinsic data correlation 을 활용해서 형성됨
    - 이런 rich self-supervised signal 을 통해 학습하기에 더 좋은 data repfresentation 을 형성할 수 있음
  - 위 두 문제를 원큐에 해결 가능한 것처럼 보임
- item attribute 같은 context information 이 다양한 형태로, 다양한 의미로 존재할 수 있는데 - 이들의 correlation 을 통합해서 처리하긴 어려움
  - 이때, MIM 은 좋은 방법이 될 수 있는데
  - effective to capture the correlation between different views of the original input by maximizing the matual information between the encoded representations of these views
    - between different views of the original input 라는 게 중요함
    - decision tree 의 information gain 과 matual information 가 비슷한 것 같음
      - 특정 정보의 등장으로 인해 엔트로피가 얼마나 줄어드는가?

# 4. Approach
- 포인트: maximizing the mutual information among different views of the raw data
- 아이디어: incorporate several elaborately designed SSL objectives
  - leaveraging effective correlation signals
- 4개의 loss 가 나옴 - 컨셉은 전부 비슷해서 첫 번째 식만 작성
  - item - arrtibute correlation - Associated Attrivute Prediction (AAP) loss
    - $L_\text{AAP} = \mathbb E_{a_j \in \mathscr A_i} [f(i, a_j) - \text{log}{\sum_{\tilde a \in {\mathscr A \backslash \mathscr A_i}} \text{exp}(f(i, \tilde a))}]$
      - $\mathscr A = \{a_1, \cdots, a_2\}$ - item i 의 attribute set
      - $a_j$ 는 $\mathscr A_i$ 의 원소임
  - sequence - item correlation
  - sequence - attribute correlation
  - sequence - segment correlation
    - word sequence 와는 달리 single target item 이 주변 아이템들과 관련이 없을 수도 있음. 단지 on sale 상품이라 샀을 수도
      - 이런 점 때문에 Cloze strategy 를 확장시켜 item subsequence 에도 적용
      - 이 item segment(sugsequence) 는 단일 item 보다 더 clear, stable 한 user 정보(preferences) 를 내포하고 있을 것임
        - segment의 context 정보와, 그걸 없앤 original sequence 의 context 정보를 매칭시키려는 것 같음. 이렇게 하면 단지 on-sale 이라 구매한 상품들보다 user 의 실제 선호도에 집중하게 될 것 같음 - 둘 다 한 user 의 history 이기 때문 -> 좀 더 전반적인 user preference 학습 가능?
          - 이런 식으로 sequence - subsequence correlation 을 모델링하는 논문이 있는지 더 찾아봐야겠음. SSL 을 사용한 논문을 읽는 게 처음인데 아주 흥미롭다

---

- 이제부터 논문 리뷰는 이런 식으로 main concept 만 정리하려고 한다. NGCF 때 시간을 너무 많이 잡아먹었어서..
- 부캠 끝나면 논문을 아주 많이 보게 될텐데, 사실 이 포스팅 정도도 많은 것 같다. 정말 핵심만 10줄 이내로 정리하는 것도 좋을 것 같다.
- 요즘 논문을 프린트해서 보는데 정말 좋다. 태블릿을 점점 안 쓰고 있다.
- SSL 관련 내용들을 찾아보고 싶고, 이제 레퍼런스 따라가는 법을 좀 알 것 같다.

---

first draft: 2023.02.03 08:45